## WszystkoSmierdzi
maja jest moim niewolnikiem w tym projekcie! Jest ode mnie gorsza i nie moze sie z tym pogodzic
#
# üéµ Enhanced Audio Event Detection System
#

**Production-ready audio event detection using ALBERT-base-v2 transformer with advanced mel-spectrogram preprocessing**

## üéØ **Project Overview**

This system implements state-of-the-art (chatgpt generated text, im sorry for blank overstatements) audio event detection using a novel (stolen from some paper) approach that combines **ALBERT transformer architecture** with **mel-spectrogram audio features**. The system can distinguish between audio events (like musical notes, speech, or specific sounds) and background noise with high accuracy.

### **Key Innovation**
- **Transformer-based Audio Processing**: First known implementation adapting ALBERT for direct audio classification via mel-spectrograms (no, stolen like I said)
- **Advanced Augmentation Pipeline**: Sophisticated audio augmentation including spectral masking, pitch shifting, and noise injection (I guess)
- **Production-Ready Infrastructure**: Professional training pipeline with early stopping, comprehensive metrics, and automated validation (Developed by 1 person, that cant finish bachelor, over couple of days. yes, production ready. yes)

### **System Status: ‚úÖ FULLY OPERATIONAL**
- **Model**: ALBERT-base-v2 with 128-dim mel-spectrogram features
- **Dataset**: 838 event samples + 7,464 background noise samples
- **Validation**: 4/4 automated tests passing
- **Performance**: Ready for training and deployment

---

## üöÄ **Quick Start**

### **1. Installation**
```bash
# Clone the repository
git clone <repository-url>
cd WszystkoSmierdzi

# Install dependencies
pip install -r requirements.txt

# Verify system integrity
python3 validate_system.py
```

### **2. Training (Recommended: Simple)**
```bash
# Quick training with default settings
python3 training_simple.py
```

### **3. Training (Advanced)**
```bash
# Full-featured training with comprehensive evaluation
python3 training_enhanced.py --event-dir dataset_current/training --noise-dir Background

# Custom configuration
python3 training_enhanced.py --config custom_config.json
```

### **4. Evaluation**
```bash
# Evaluate trained model
python3 evaluate.py --model-path ./models/audio_albert_classifier --data-dir dataset_current/test
```

---

## üèóÔ∏è **System Architecture**

### **High-Level Architecture**
```mermaid
graph TD
    A[Audio Input 16kHz WAV] --> B[Mel-Spectrogram Extraction]
    B --> C[Feature Projection Layer]
    C --> D[ALBERT Transformer albert-base-v2]
    D --> E[Classification Head]
    E --> F[Event/No-Event Prediction]
    
    G[Data Augmentation] --> B
    H[Background Noise] --> G
```

### **Model Pipeline**
1. **Audio Preprocessing**: 16kHz WAV ‚Üí 128-dimensional mel-spectrograms
2. **Feature Projection**: Map mel-features to ALBERT's 768-dim embedding space
3. **Transformer Processing**: ALBERT-base-v2 processes audio sequences
4. **Classification**: Binary classification head outputs event probability

### **Training Infrastructure**
- **Early Stopping**: Prevents overfitting with configurable patience
- **Mixed Precision**: FP16 training for faster convergence
- **Comprehensive Metrics**: Accuracy, precision, recall, F1-score, ROC-AUC
- **Model Checkpointing**: Automatic saving of best performing models

---

## üìÅ **Core Components**

### **üß† AI/ML Core**
| Component | Purpose | Key Features |
|-----------|---------|--------------|
| `model.py` | ALBERT-based audio classifier | Mel-spectrogram integration, temporal pooling |
| `dataset.py` | Audio preprocessing pipeline | Advanced augmentation, caching, balanced sampling |
| `utils.py` | Metrics and evaluation tools | Multi-metric evaluation, visualization |
| `config.py` | Configuration management | JSON-based, hierarchical configuration |

### **üéì Training Scripts**
| Script | Use Case | Features |
|--------|----------|----------|
| `training_simple.py` | Quick start training | Minimal setup, fast execution |
| `training_enhanced.py` | Production training | Full features, comprehensive logging |
| `validate_system.py` | System health checks | Automated validation, 4-test suite |

### **üìä Data & Configuration**
| Component | Purpose | Contents |
|-----------|---------|----------|
| `config_default.json` | Default parameters | Audio, model, training, data settings |
| `dataset_current/` | Main dataset | 838 event samples (Bebop, Membo, Mixed) |
| `Background/` | Noise samples | 7,464 background audio files |
| `requirements.txt` | Dependencies | PyTorch, Transformers, audio libraries |

---

## ‚öôÔ∏è **Configuration**

The system uses hierarchical JSON configuration:

```json
{
  "audio": {
    "sample_rate": 16000,
    "max_duration": 10.0,
    "n_mels": 128,
    "n_fft": 2048,
    "hop_length": 512
  },
  "model": {
    "model_name": "albert-base-v2",
    "num_labels": 2,
    "max_position_embeddings": 512,
    "freeze_base_model": false
  },
  "training": {
    "num_train_epochs": 20,
    "learning_rate": 2e-5,
    "per_device_train_batch_size": 16,
    "early_stopping_patience": 5,
    "fp16": true
  },
  "augmentation": {
    "enable": true,
    "noise_prob": 0.5,
    "gain_range": [0.5, 1.5],
    "pitch_shift_prob": 0.2
  }
}
```

---

## üéõÔ∏è **Advanced Features**

### **Audio Processing**
- **Mel-Spectrograms**: 128 mel-frequency bins optimized for music/speech
- **Smart Duration Handling**: Automatic padding/cropping to fixed length
- **Multi-format Support**: WAV, FLAC support with automatic resampling

### **Data Augmentation**
- **Spectral Augmentation**: Time/frequency masking
- **Audio Augmentation**: Gain variation, noise injection, pitch shifting
- **Background Mixing**: Intelligent noise mixing with configurable levels

### **Training Features**
- **Balanced Sampling**: Handle imbalanced datasets automatically
- **Feature Caching**: Speed up training with intelligent caching
- **GPU Optimization**: CUDA support with mixed precision training
- **Comprehensive Logging**: Detailed training progress and metrics

---

## üìä **Usage Examples**

### **Custom Training**
```python
from config import ExperimentConfig
from training_enhanced import train_model

# Load and modify configuration
config = ExperimentConfig.from_json("config_default.json")
config.training.learning_rate = 1e-5
config.training.num_train_epochs = 30

# Start training
results = train_model(config)
```

### **Single File Prediction**
```python
from training_enhanced import predict_audio_event

# Predict on new audio file
result = predict_audio_event(
    audio_path="path/to/audio.wav",
    model_path="./models/audio_albert_classifier"
)

print(f"Prediction: {result['predicted_label']}")
print(f"Confidence: {result['confidence']:.3f}")
```

### **Batch Evaluation**
```python
from utils import evaluate_model_comprehensive

# Comprehensive model evaluation
metrics = evaluate_model_comprehensive(
    model=model,
    eval_dataloader=dataloader,
    device=device,
    output_dir="evaluation_results/"
)
```

---

## üìä **System Validation**

**Automated Health Checks:**
```bash
python3 validate_system.py
```

**Expected Output:**
```
‚úÖ Module Imports: PASSED
‚úÖ Configuration System: PASSED  
‚úÖ Model Creation: PASSED
‚úÖ Audio Processing: PASSED
Overall: 4/4 tests passed - System ready for operation
```

---

## üîß **Development Setup**

### **Environment Requirements**
- **Python**: 3.8+ (recommended: 3.10)
- **PyTorch**: 2.0+ with CUDA support (optional)
- **Memory**: 8GB RAM minimum, 16GB recommended
- **Storage**: 5GB for datasets + models

### **Development Tools**
```bash
# Code formatting
black *.py

# Linting
flake8 *.py

# Testing
pytest validate_system.py
```

---

## üöß **Troubleshooting**

### **Common Issues**

| Issue | Solution |
|-------|----------|
| **CUDA out of memory** | Reduce `per_device_train_batch_size` in config |
| **Audio format errors** | Ensure 16kHz WAV format, check with `ffprobe` |
| **Import errors** | Run `pip install -r requirements.txt` |
| **Model not converging** | Check learning rate, enable data augmentation |

### **Performance Optimization**
- **GPU Training**: Ensure CUDA-compatible PyTorch installation
- **Faster Loading**: Enable feature caching for repeated experiments  
- **Memory Efficiency**: Use gradient accumulation for large batch sizes
- **Data Preprocessing**: Use multiple workers (`dataloader_num_workers: 4`)

---

## üìà **Performance Metrics**

The system provides comprehensive evaluation metrics:

- **Classification Metrics**: Accuracy, Precision, Recall, F1-Score
- **Probabilistic Metrics**: ROC-AUC, Confidence Intervals
- **Per-Class Analysis**: Class-specific performance breakdown
- **Confusion Matrices**: Visual performance analysis
- **Training Curves**: Loss and metric progression plots

---

## üîÑ **Migration from Previous Versions**

| Component | Previous | Enhanced |
|-----------|----------|----------|
| **Model** | wav2vec2-base | ALBERT-base-v2 |
| **Features** | Basic audio | 128-dim mel-spectrograms |
| **Training** | Simple loop | Professional pipeline |
| **Config** | Hardcoded values | JSON-based system |
| **Evaluation** | Basic accuracy | Comprehensive metrics |

**Migration Command:**
```bash
# Use enhanced training instead of old training.py
python3 training_enhanced.py  # instead of training.py
```

---

## üìö **Dependencies**

**Core ML Libraries:**
- `torch>=2.0.0` - Deep learning framework
- `transformers>=4.30.0` - Hugging Face transformers
- `torchaudio>=2.0.0` - Audio processing

**Audio Processing:**
- `librosa>=0.10.0` - Advanced audio analysis
- `soundfile>=0.12.0` - Audio I/O
- `pydub>=0.25.0` - Audio manipulation

**Data Science:**
- `numpy>=1.24.0`, `pandas>=2.0.0`, `scikit-learn>=1.3.0`
- `matplotlib>=3.7.0`, `seaborn>=0.12.0` - Visualization

See `requirements.txt` for complete dependency list.

---

## üìù **License & Citation**

If you use this work, please cite:

```
@misc{wszystkowsmierdzi2025,
    title   = {Enhanced Audio Event Detection System using ALBERT-base-v2},
    author  = {Kuba and contributors},
    year    = {2025},
    howpublished = {\url{https://github.com/your-repo-url}},
    note    = {WszystkoSmierdzi Project}
}
```

---

## ü§ù **Contributing**

1. **Fork** the repository
2. **Create** feature branch (`git checkout -b feature/amazing-feature`)
3. **Test** your changes (`python3 validate_system.py`)
4. **Commit** changes (`git commit -m 'Add amazing feature'`)
5. **Push** to branch (`git push origin feature/amazing-feature`)
6. **Open** Pull Request

### **Development Guidelines**
- Follow PEP 8 style guidelines
- Add comprehensive docstrings
- Include unit tests for new features
- Update documentation for API changes

---

**Status**: Production Ready ‚Ä¢ **Tests**: 4/4 Passing ‚úÖ ‚Ä¢ **Last Updated**: June 2025
